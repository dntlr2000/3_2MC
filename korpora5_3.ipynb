{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lX8AymXIxZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b34a0d-3be1-4f8a-9f34-e0caa43c7264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Kopara'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "python3: can't open file '/content/setup.py': [Errno 2] No such file or directory\n",
            "Requirement already satisfied: Korpora in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.10/dist-packages (from Korpora) (0.6)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (4.66.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.32.3)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->Korpora) (2024.8.30)\n",
            "--2024-12-01 11:51:01--  https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889842 (869K) [text/plain]\n",
            "Saving to: ‘ChatbotData.csv.1’\n",
            "\n",
            "ChatbotData.csv.1   100%[===================>] 868.99K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-12-01 11:51:01 (123 MB/s) - ‘ChatbotData.csv.1’ saved [889842/889842]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ko-nlp/Kopara\n",
        "!python setup.py install\n",
        "!pip install Korpora\n",
        "\n",
        "from Korpora import Korpora\n",
        "!wget https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKV6lgvmIzTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f3156f-187e-41c8-c7ac-c63f608f8642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Q            A  label\n",
            "0           12시 땡!   하루가 또 가네요.      0\n",
            "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
            "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
            "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
            "4          PPL 심하네   눈살이 찌푸려지죠.      0\n",
            "데이터 개수: 11823\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "data = pd.read_csv('ChatbotData.csv')\n",
        "\n",
        "print(data.head())\n",
        "print('데이터 개수:', len(data))\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "questions = data['Q'].tolist()\n",
        "answers = data['A'].tolist()\n",
        "labels = data['label'].tolist() #일상:0, 사랑:1, 이별:2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEnej1eoLCGP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r\"[^0-9가-힣a-zA-Z?.!,¿]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence\n",
        "\n",
        "questions = [preprocess_sentence(q) for q in questions]\n",
        "answers = [preprocess_sentence(a) for a in answers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BSLLEULVSE"
      },
      "outputs": [],
      "source": [
        "START_TOKEN = '<sos> '\n",
        "END_TOKEN = ' <eos>'\n",
        "\n",
        "answers = [START_TOKEN + a + END_TOKEN for a in answers]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WfRW-cgLVtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c87f438-65b3-4530-c6fe-7e9e69b0d985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 사전 크기: 21746\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(filters='', oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print('단어 사전 크기:', VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDfTWhF8LXBg"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 40  # 최대 문장 길이 설정\n",
        "\n",
        "# 시퀀스 변환\n",
        "question_sequences = tokenizer.texts_to_sequences(questions)\n",
        "answer_sequences = tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "# 패딩\n",
        "question_inputs = pad_sequences(question_sequences, maxlen=MAX_LENGTH, padding='post')\n",
        "answer_inputs = pad_sequences(answer_sequences, maxlen=MAX_LENGTH, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYBMdIxxLYKX"
      },
      "outputs": [],
      "source": [
        "answer_targets = [seq[1:] for seq in answer_sequences]\n",
        "answer_targets = pad_sequences(answer_targets, maxlen=MAX_LENGTH, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpHK2SLkLa0G"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_q, val_q, train_a_in, val_a_in, train_a_out, val_a_out = train_test_split(\n",
        "    question_inputs, answer_inputs, answer_targets, test_size=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeNoadULLcQZ"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "units = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9TbF-j4LexT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Input\n",
        "\n",
        "# 인코더 입력\n",
        "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
        "\n",
        "# 임베딩 레이어\n",
        "enc_emb = Embedding(VOCAB_SIZE, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "encoder_lstm = LSTM(units, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# 인코더 상태 저장\n",
        "encoder_states = [state_h, state_c]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtgC_Pj2LgwW"
      },
      "outputs": [],
      "source": [
        "# 디코더 입력\n",
        "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "\n",
        "# 임베딩 레이어\n",
        "dec_emb_layer = Embedding(VOCAB_SIZE, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "decoder_lstm = LSTM(units, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# 출력 레이어\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "decoder_dense = Dense(VOCAB_SIZE, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 감정 분석 레이어\n",
        "emotion_dense = Dense(3, activation='softmax', name='emotion_dense')\n",
        "emotion_output = emotion_dense(encoder_outputs)  # 인코더의 출력을 입력으로 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "_1XSaqpfLivM",
        "outputId": "2549ba99-50cd-42b0-b0c8-d15f4bfdfc32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,566,976\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m5,566,976\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21746\u001b[0m)    │     \u001b[38;5;34m11,155,698\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ emotion_dense (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │          \u001b[38;5;34m1,539\u001b[0m │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,566,976</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,566,976</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21746</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,155,698</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ emotion_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,441,013\u001b[0m (97.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,441,013</span> (97.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,441,013\u001b[0m (97.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,441,013</span> (97.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], [decoder_outputs, emotion_output])\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'decoder_dense': 'sparse_categorical_crossentropy', 'emotion_dense': 'sparse_categorical_crossentropy'},\n",
        "              loss_weights={'decoder_dense': 1.0, 'emotion_dense': 0.5})\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMzXi4TmLkKB",
        "outputId": "3a9c0f3a-5641-4dd5-a736-df6f645f60bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 151ms/step - decoder_dense_loss: 2.4395 - emotion_dense_loss: 0.5440 - loss: 2.9835 - val_decoder_dense_loss: 0.8999 - val_emotion_dense_loss: 0.5459 - val_loss: 1.4496\n",
            "Epoch 2/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 133ms/step - decoder_dense_loss: 0.8592 - emotion_dense_loss: 0.5365 - loss: 1.3957 - val_decoder_dense_loss: 0.8880 - val_emotion_dense_loss: 0.5366 - val_loss: 1.4282\n",
            "Epoch 3/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 139ms/step - decoder_dense_loss: 0.8223 - emotion_dense_loss: 0.5389 - loss: 1.3612 - val_decoder_dense_loss: 0.8897 - val_emotion_dense_loss: 0.5372 - val_loss: 1.4302\n",
            "Epoch 4/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 143ms/step - decoder_dense_loss: 0.7849 - emotion_dense_loss: 0.5379 - loss: 1.3229 - val_decoder_dense_loss: 0.8995 - val_emotion_dense_loss: 0.5376 - val_loss: 1.4403\n",
            "Epoch 5/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 144ms/step - decoder_dense_loss: 0.7530 - emotion_dense_loss: 0.5349 - loss: 1.2879 - val_decoder_dense_loss: 0.9126 - val_emotion_dense_loss: 0.5370 - val_loss: 1.4526\n",
            "Epoch 6/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 147ms/step - decoder_dense_loss: 0.7267 - emotion_dense_loss: 0.5356 - loss: 1.2623 - val_decoder_dense_loss: 0.9264 - val_emotion_dense_loss: 0.5392 - val_loss: 1.4693\n",
            "Epoch 7/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - decoder_dense_loss: 0.7052 - emotion_dense_loss: 0.5376 - loss: 1.2428 - val_decoder_dense_loss: 0.9427 - val_emotion_dense_loss: 0.5380 - val_loss: 1.4842\n",
            "Epoch 8/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 145ms/step - decoder_dense_loss: 0.6821 - emotion_dense_loss: 0.5349 - loss: 1.2170 - val_decoder_dense_loss: 0.9663 - val_emotion_dense_loss: 0.5372 - val_loss: 1.5073\n",
            "Epoch 9/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 142ms/step - decoder_dense_loss: 0.6525 - emotion_dense_loss: 0.5349 - loss: 1.1873 - val_decoder_dense_loss: 0.9349 - val_emotion_dense_loss: 0.5143 - val_loss: 1.4528\n",
            "Epoch 10/10\n",
            "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 147ms/step - decoder_dense_loss: 0.6288 - emotion_dense_loss: 0.4778 - loss: 1.1066 - val_decoder_dense_loss: 0.9401 - val_emotion_dense_loss: 0.4288 - val_loss: 1.3718\n"
          ]
        }
      ],
      "source": [
        "#질문, 답변 입력 및 타겟 시퀀스\n",
        "train_q, val_q, train_a_in, val_a_in, train_a_out, val_a_out, train_labels, val_labels = train_test_split(\n",
        "    question_inputs, answer_inputs, answer_targets, labels, test_size=0.1)\n",
        "\n",
        "# 타겟 데이터에 차원 추가\n",
        "train_a_out = np.expand_dims(train_a_out, -1)\n",
        "val_a_out = np.expand_dims(val_a_out, -1)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    {'encoder_inputs': np.array(train_q), 'decoder_inputs': np.array(train_a_in)},  # Pass inputs as a dictionary\n",
        "    {'decoder_dense': train_a_out, 'emotion_dense': np.array(train_labels)},  # Convert labels to NumPy array\n",
        "    validation_data=({'encoder_inputs': np.array(val_q), 'decoder_inputs': np.array(val_a_in)},\n",
        "                     {'decoder_dense': val_a_out, 'emotion_dense': np.array(val_labels)}),\n",
        "    batch_size=64,\n",
        "    epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfwZDbJLpyE"
      },
      "outputs": [],
      "source": [
        "# 인퍼런스 인코더\n",
        "encoder_model = Model(encoder_inputs, [encoder_states, emotion_output])\n",
        "\n",
        "# 인퍼런스 디코더 입력\n",
        "decoder_state_input_h = Input(shape=(units,))\n",
        "decoder_state_input_c = Input(shape=(units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(\n",
        "    dec_emb2, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cDDnF4d-LyDM"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 인코더를 통해 상태 벡터와 감정 예측 얻기\n",
        "    encoder_outputs = encoder_model.predict(input_seq)\n",
        "    states_value, predicted_emotion = encoder_outputs[0], encoder_outputs[1]\n",
        "\n",
        "    # 감정 예측 결과를 기반으로 맞춤형 응답 제공\n",
        "    emotion_index = np.argmax(predicted_emotion[0])\n",
        "    #emotion_text = {0: \"일상\", 1: \"긍정\", 2: \"부정\"}[emotion_index]\n",
        "    emotion_text = {0: \"\", 1: \"\", 2: \"\"}[emotion_index]\n",
        "\n",
        "    # 목표 시퀀스 초기화 (시작 토큰의 인덱스)\n",
        "    start_token_index = tokenizer.word_index.get(START_TOKEN.strip(), 1)  # OOV 방지를 위해 기본값 1 설정\n",
        "    target_seq = np.array([[start_token_index]])  # 모양을 (1, 1)로 지정\n",
        "\n",
        "    # 결과 저장용 변수\n",
        "    #decoded_sentence = f\"[{emotion_text}] \"\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    while True:\n",
        "        # 디코더 모델에 입력 상태 전달 (감정 출력 제거)\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과에서 단어 인덱스 추출\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, '<UNK>')\n",
        "\n",
        "        # 종료 조건 확인: 종료 토큰이거나 최대 길이 초과\n",
        "        if (sampled_word == END_TOKEN.strip()) or (len(decoded_sentence.split()) > MAX_LENGTH):\n",
        "            break\n",
        "\n",
        "        # 결과 문장에 단어 추가\n",
        "        decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "        # 목표 시퀀스 업데이트 (모양을 (1, 1)로 유지)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "        # 상태 업데이트\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 감정 분류 모델 정의 및 로드\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert, hidden_size=768, num_classes=3, dr_rate=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "        self.classifier = torch.nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        _, pooled_output = self.bert(\n",
        "            input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=False\n",
        "        )\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# 모델 초기화\n",
        "bert_model = BERTClassifier(bert=bert)\n",
        "\n",
        "# state_dict 로드\n",
        "checkpoint = torch.load('emotion_classification_model.pt')\n",
        "\n",
        "# 필요한 키만 로드\n",
        "model_state_dict = bert_model.state_dict()\n",
        "filtered_checkpoint = {k: v for k, v in checkpoint.items() if k in model_state_dict and v.size() == model_state_dict[k].size()}\n",
        "model_state_dict.update(filtered_checkpoint)\n",
        "\n",
        "# 업데이트된 state_dict 로드\n",
        "bert_model.load_state_dict(model_state_dict)\n",
        "bert_model.eval()\n",
        "\n",
        "b_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# 감정 분류 함수\n",
        "def predict_emotion(text):\n",
        "    inputs = b_tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)  # 올바른 모델 이름 사용\n",
        "        logits = outputs\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        predicted_label = torch.argmax(probs, dim=-1).item()\n",
        "    labels = ['일상(_)', '사랑(긍정)', '이별(부정)']\n",
        "    return labels[predicted_label]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF02-Bnj2JFQ",
        "outputId": "269dc004-d6ee-4158-b66e-735c1c6121d2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-74d18efe7382>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('emotion_classification_model.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "lmHvp4SeL17J"
      },
      "outputs": [],
      "source": [
        "\n",
        "def chatbot_response(input_sentence):\n",
        "    # 1. 입력 문장 전처리\n",
        "    input_sentence_processed = preprocess_sentence(input_sentence)\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_sentence_processed])\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    # 2. 감정 분류\n",
        "    emotion = predict_emotion(input_sentence)  # 감정 분류 모델 호출\n",
        "\n",
        "    # 3. 응답 생성\n",
        "    response = decode_sequence(input_padded)  # 기존 응답 생성 로직\n",
        "\n",
        "    # 4. 감정 분류 결과 포함\n",
        "    final_response = f\"[{emotion}] {response}\"  # 감정 결과를 대괄호로 표시\n",
        "    #final_response = f\"{response}\"\n",
        "\n",
        "    return final_response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 테스트\n",
        "\n",
        "while True:\n",
        "    input_sentence = input('You: ')\n",
        "    if input_sentence == 'exit':\n",
        "        break\n",
        "    response = chatbot_response(input_sentence)\n",
        "    print('Chatbot:', response)\n"
      ],
      "metadata": {
        "id": "EX5Yp2OH_DFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c609f6b4-7b4d-4c35-a78d-a2208c5fde36"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: 오늘 선생님께 혼이 나서 슬퍼\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Chatbot: [일상]  다른 위한 위해 건 없어요.\n",
            "You: 어제 연인이랑 헤어졌어\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Chatbot: [일상]  제가 생각을 마세요.\n",
            "You: 오늘은 아주 특별한 날이라 설레\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Chatbot: [일상]  자신과 진실로 존중하고 그런 것\n",
            "You: 친구랑 다퉜어\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Chatbot: [일상]  지금처럼 있지 돼요.\n",
            "You: 그대 생각만 나는걸\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Chatbot: [긍정]  조금만 것을 습관이에요.\n",
            "You: PPL이 너무 많아서 짜증나\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Chatbot: [일상]  그런 사람은 말 있어요.\n",
            "You: 이제 뭘 해야 할까\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Chatbot: [일상]  당신은 그렇게 많이 해요.\n",
            "You: 대답 똑바로 안하니\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Chatbot: [긍정]  충분히 충분히 슬픈 있어요.\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = '친구랑 크게 다퉜어 그래서 어쩔건데'\n",
        "user_input = '친구랑 크게 다퉜어'\n",
        "response = chatbot_response(input_sentence)\n",
        "print('Chatbot:', response)"
      ],
      "metadata": {
        "id": "RRQmqIRD_D9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52dd13a3-c5d9-4ef7-df78-922bd8a8e8bf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Chatbot: [이별(부정)] 좋은\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DD1wFTjL_P3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}